{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torchvision\n",
    "from skimage import io, transform\n",
    "from skimage import color\n",
    "import scipy.misc\n",
    "import scipy.ndimage as ndi\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from pytvision import visualization as view\n",
    "from pytvision.transforms import transforms as mtrans\n",
    "from tqdm import tqdm\n",
    "sys.path.append('../')\n",
    "from torchlib.datasets import dsxbdata\n",
    "from torchlib.datasets.dsxbdata import DSXBExDataset, DSXBDataset\n",
    "from torchlib.datasets import imageutl as imutl\n",
    "from torchlib import utils\n",
    "from torchlib.models import unetpad\n",
    "from torchlib.metrics import get_metrics\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#matplotlib.style.use('fivethirtyeight')\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "from pytvision.transforms import transforms as mtrans\n",
    "from torchlib import metrics\n",
    "\n",
    "from torchlib.segneuralnet import SegmentationNeuralNet\n",
    "from torchlib import post_processing_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "map_post  = post_processing_func.MAP_post()\n",
    "th_post   = post_processing_func.TH_post()\n",
    "wts_post  = post_processing_func.WTS_post()\n",
    "\n",
    "normalize = mtrans.ToMeanNormalization(\n",
    "    mean = (0.485, 0.456, 0.406),  \n",
    "    std  = (0.229, 0.224, 0.225), \n",
    "    )\n",
    "\n",
    "class NormalizeInverse(torchvision.transforms.Normalize):\n",
    "    \"\"\"\n",
    "    Undoes the normalization and returns the reconstructed images in the input domain.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mean = (0.485, 0.456, 0.406), std  = (0.229, 0.224, 0.225)):\n",
    "        mean     = torch.as_tensor(mean)\n",
    "        std      = torch.as_tensor(std)\n",
    "        std_inv  = 1 / (std + 1e-7)\n",
    "        mean_inv = -mean * std_inv\n",
    "        super().__init__(mean=mean_inv, std=std_inv)\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        return super().__call__(tensor.clone())\n",
    "\n",
    "n = NormalizeInverse()\n",
    "\n",
    "def get_simple_transforms(pad=0):\n",
    "    return transforms.Compose([\n",
    "        #mtrans.CenterCrop( (1008, 1008) ),\n",
    "        mtrans.ToPad( pad, pad, padding_mode=cv2.BORDER_CONSTANT ),\n",
    "        mtrans.ToTensor(),\n",
    "        normalize,      \n",
    "    ])\n",
    "\n",
    "\n",
    "def get_flip_transforms(pad=0):\n",
    "    return transforms.Compose([\n",
    "        #mtrans.CenterCrop( (1008, 1008) ),\n",
    "        mtrans.ToRandomTransform( mtrans.VFlip(), prob=0.5 ),\n",
    "        mtrans.ToRandomTransform( mtrans.HFlip(), prob=0.5 ),\n",
    "        \n",
    "        mtrans.ToPad( pad, pad, padding_mode=cv2.BORDER_CONSTANT ),\n",
    "        mtrans.ToTensor(),\n",
    "        normalize,      \n",
    "    ])\n",
    "\n",
    "def tensor2image(tensor, norm_inverse=True):\n",
    "    if tensor.dim() == 4:\n",
    "        tensor = tensor[0]\n",
    "    if norm_inverse:\n",
    "            tensor = n(tensor)\n",
    "    img = tensor.cpu().numpy().transpose(1,2,0)\n",
    "    img = (img * 255).clip(0, 255).astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "def show(src, titles=[], suptitle=\"\", \n",
    "         bwidth=4, bheight=4, save_file=False,\n",
    "         show_axis=True, show_cbar=False, last_max=0):\n",
    "\n",
    "    num_cols = len(src)\n",
    "    \n",
    "    plt.figure(figsize=(bwidth * num_cols, bheight))\n",
    "    plt.suptitle(suptitle)\n",
    "\n",
    "    for idx in range(num_cols):\n",
    "        plt.subplot(1, num_cols, idx+1)\n",
    "        if not show_axis: plt.axis(\"off\")\n",
    "        if idx < len(titles): plt.title(titles[idx])\n",
    "        \n",
    "        if idx == num_cols-1 and last_max:\n",
    "            plt.imshow(src[idx]*1, vmax=last_max, vmin=0)\n",
    "        else:\n",
    "            plt.imshow(src[idx]*1)\n",
    "        if type(show_cbar) is bool:\n",
    "            if show_cbar: plt.colorbar()\n",
    "        elif idx < len(show_cbar) and show_cbar[idx]:\n",
    "            plt.colorbar()\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    if save_file:\n",
    "        plt.savefig(save_file)\n",
    "        \n",
    "def show2(src, titles=[], suptitle=\"\", \n",
    "         bwidth=4, bheight=4, save_file=False,\n",
    "         show_axis=True, show_cbar=False, last_max=0):\n",
    "\n",
    "    num_cols = len(src)//2\n",
    "    \n",
    "    plt.figure(figsize=(bwidth * num_cols, bheight*2))\n",
    "    plt.suptitle(suptitle)\n",
    "\n",
    "    for idx in range(num_cols*2):\n",
    "        plt.subplot(2, num_cols, idx+1)\n",
    "        if not show_axis: plt.axis(\"off\")\n",
    "        if idx < len(titles): plt.title(titles[idx])\n",
    "        \n",
    "        if idx == num_cols-1 and last_max:\n",
    "            plt.imshow(src[idx]*1, vmax=last_max, vmin=0)\n",
    "        else:\n",
    "            plt.imshow(src[idx]*1)\n",
    "        if type(show_cbar) is bool:\n",
    "            if show_cbar: plt.colorbar()\n",
    "        elif idx < len(show_cbar) and show_cbar[idx]:\n",
    "            plt.colorbar()\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    if save_file:\n",
    "        plt.savefig(save_file)\n",
    "        \n",
    "def get_diversity_map(preds, gt_predictionlb, th=0.5):\n",
    "    max_iou = 0\n",
    "    diversity_map = np.zeros_like(gt_predictionlb)\n",
    "    for idx_gt in range(1, gt_predictionlb.max()):\n",
    "        roi = (gt_predictionlb==idx_gt)\n",
    "        max_iou = 0\n",
    "\n",
    "        for predlb in preds:\n",
    "            for idx_pred in range(1, predlb.max()):\n",
    "                roi_pred  = (predlb==idx_pred)\n",
    "                union = roi.astype(int) + roi_pred.astype(int)\n",
    "                val, freq = np.unique(union, return_counts=True)\n",
    "\n",
    "                if len(val)==3:\n",
    "                    iou = freq[2]/(freq[1]+freq[2])\n",
    "                    if iou > max_iou:\n",
    "                        max_iou = iou\n",
    "                if max_iou > th: break\n",
    "            if max_iou >th:\n",
    "                diversity_map += roi\n",
    "    return diversity_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathdataset      = os.path.expanduser( '/home/chcp/Datasets' )\n",
    "#namedataset      = 'Seg33_1.0.4'\n",
    "#namedataset      = 'Seg1009_0.3.2'\n",
    "namedataset      = 'FluoC2DLMSC_0.1.1'\n",
    "#namedataset      = 'Bfhsc_1.0.0'\n",
    "#'Segments_Seg1009_0.3.2_unetpad_jreg__adam_map_ransac2_1_7_1'\n",
    "\n",
    "#namedataset      = 'FluoC2DLMSC_0.0.1'\n",
    "sub_folder       = 'test'\n",
    "folders_images   = 'images'\n",
    "folders_contours = 'touchs'\n",
    "folders_weights  = 'weights'\n",
    "folders_segment  = 'outputs'\n",
    "num_classes      = 4\n",
    "num_channels     = 3\n",
    "pad              = 0\n",
    "pathname         = pathdataset + '//' + namedataset\n",
    "subset           = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list =  [Path(url).name for url in glob(r'/home/chcp/Code/pytorch-unet/out/Fluo/baseline_*')\n",
    "for model_url_base in tqdm(model_list):\n",
    "    pathmodel = r'/home/chcp/Code/pytorch-unet/out/Fluo/'\n",
    "    ckpt      = r'/models/model_best.pth.tar'\n",
    "\n",
    "    net = SegmentationNeuralNet(\n",
    "        patchproject=pathmodel, \n",
    "        nameproject=model_url_base, \n",
    "        no_cuda=False, parallel=False,\n",
    "        seed=2021, print_freq=False,\n",
    "        gpu=2\n",
    "        )\n",
    "    \n",
    "\n",
    "    if net.load( pathmodel+model_url_base+ckpt ) is not True:\n",
    "        print(\"Not Found Warring: \", pathmodel,model_url_base,ckpt)\n",
    "        continue\n",
    "    Path(f\"extra/{model_url_base}\").mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    for subset in ['test', 'train', 'val']:\n",
    "    \n",
    "        test_data = dsxbdata.ISBIDataset(\n",
    "            pathname, \n",
    "            subset, \n",
    "            folders_labels=f'labels{num_classes}c',\n",
    "            count=None,\n",
    "            num_classes=num_classes,\n",
    "            num_channels=num_channels,\n",
    "            transform=get_simple_transforms(pad=0),\n",
    "            use_weight=False,\n",
    "            weight_name='',\n",
    "            load_segments=False,\n",
    "            shuffle_segments=True,\n",
    "            use_ori=1\n",
    "        )\n",
    "        \n",
    "\n",
    "\n",
    "        test_loader = DataLoader(test_data, batch_size=1, shuffle=False, \n",
    "            num_workers=0, pin_memory=True, drop_last=False)\n",
    "\n",
    "        softmax = torch.nn.Softmax(dim=0)\n",
    "        \n",
    "        wpq, wsq, wrq, total_cells = 0, 0, 0, 0\n",
    "\n",
    "        for idx, sample in enumerate(test_loader):\n",
    "            inputs, labels = sample['image'], sample['label']\n",
    "            \n",
    "            inputs  = inputs.cuda(2)\n",
    "            outputs = net(inputs).cpu()\n",
    "            amax        = outputs[0].argmax(0)\n",
    "            view_inputs = tensor2image(inputs[0, :3])\n",
    "            view_labels = labels[0].argmax(0)\n",
    "            prob = outputs[0] / outputs[0].sum(0)\n",
    "            \n",
    "            \n",
    "            results, n_cells, preds = get_metrics(labels, outputs, post_label='map')\n",
    "            predictionlb, prediction, region, output = preds\n",
    "            \n",
    "            wpq += results['pq'] * n_cells\n",
    "            wsq += results['sq'] * n_cells\n",
    "            wrq += results['rq'] * n_cells\n",
    "            total_cells += n_cells\n",
    "            \n",
    "            res_str = f\"Nreal {n_cells} | Npred {results['n_cells']} | PQ {results['pq']:0.2f} \" + \\\n",
    "                    f\"| SQ {results['sq']:0.2f} | RQ {results['rq']:0.2f}\"\n",
    "            \n",
    "            show2([view_inputs, view_labels, amax, predictionlb, prob[0], prob[1], prob[2], prob[3]], show_axis=False, suptitle=res_str,\n",
    "                 show_cbar=[False, False, False, False, True, True, True, True], save_file=f\"extra/{model_url_base}/{namedataset}_{subset}_{idx}.jpg\",\n",
    "                 titles=['Original', 'Label', 'MAP', 'Cells', 'Prob 0', 'Prob 1', 'Prob 2', 'Prob 3'], bheight=4.5)\n",
    "            \n",
    "\n",
    "        row = [namedataset, subset, model_url_base, wpq/total_cells, wsq/total_cells, wrq/total_cells, total_cells]\n",
    "        row = list(map(str, row))\n",
    "        header = [\"dataset\", 'subset', 'model', 'WPQ', 'WSQ', \"WRQ\", \"Cells\"]\n",
    "        save_file=f\"extra/{model_url_base}\"\n",
    "        \n",
    "        summary_log = \"extra/summary.csv\"\n",
    "        \n",
    "        write_header = not Path(summary_log).exists()\n",
    "        with open(summary_log, 'a') as f:\n",
    "            if write_header:\n",
    "                f.writelines(','.join(header)+'\\n')\n",
    "            f.writelines(','.join(row)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
