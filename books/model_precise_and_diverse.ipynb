{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5020b4a4e1af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/skimage/transform/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                               \u001b[0mprobabilistic_hough_line\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhough_circle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                               hough_circle_peaks, hough_ellipse)\n\u001b[0;32m----> 4\u001b[0;31m from .radon_transform import (radon, iradon, iradon_sart,\n\u001b[0m\u001b[1;32m      5\u001b[0m                               order_angles_golden_ratio)\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfinite_radon_transform\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfrt2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mifrt2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/skimage/transform/radon_transform.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minterp1d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstants\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgolden_ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_warps\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_radon_transform\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msart_projection_update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shared\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfft\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfftmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/skimage/transform/_warps.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                          ProjectiveTransform, _to_ndimage_mode)\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_warps_cy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_warp_fast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeasure\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mblock_reduce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m from .._shared.utils import (get_bound_method_class, safe_as_int, warn,\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/skimage/measure/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m from ._regionprops import (regionprops, perimeter,\n\u001b[1;32m      6\u001b[0m                            perimeter_crofton, euler_number, regionprops_table)\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_polygon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapproximate_polygon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdivide_polygon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpnpoly\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpoints_in_poly\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_points_in_poly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m from ._moments import (moments, moments_central, moments_coords,\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/skimage/measure/_polygon.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msignal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mapproximate_polygon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/scipy/signal/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mspectral\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwavelets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_peak_finding\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwindows\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_window\u001b[0m  \u001b[0;31m# keep this one in signal namespace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/scipy/signal/_peak_finding.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwavelets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcwt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mricker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscoreatpercentile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m from ._peak_finding_utils import (\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/scipy/stats/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \"\"\"\n\u001b[0;32m--> 388\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmorestats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/scipy/stats/stats.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mspecial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmstats_basic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m from ._stats_mstats_common import (_find_repeats, linregress, theilslopes,\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/scipy/stats/distributions.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_continuous_distns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_discrete_distns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_continuous_distns\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/scipy/stats/_discrete_distns.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m dlaplace = dlaplace_gen(a=-np.inf,\n\u001b[0;32m--> 963\u001b[0;31m                         name='dlaplace', longname='A discrete Laplacian')\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, a, b, name, badvalue, moment_tol, values, inc, longname, shapes, extradoc, seed)\u001b[0m\n\u001b[1;32m   2878\u001b[0m                                   \u001b[0mlocscale_in\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loc=0'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2879\u001b[0m                                   \u001b[0;31m# scale=1 for discrete RVs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2880\u001b[0;31m                                   locscale_out='loc, 1')\n\u001b[0m\u001b[1;32m   2881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2882\u001b[0m         \u001b[0;31m# nin correction needs to be after we know numargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py\u001b[0m in \u001b[0;36m_construct_argparser\u001b[0;34m(self, meths_to_inspect, locscale_in, locscale_out)\u001b[0m\n\u001b[1;32m    699\u001b[0m                    )\n\u001b[1;32m    700\u001b[0m         \u001b[0mns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m         \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparse_arg_template\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m         \u001b[0;31m# NB: attach to the instance, not class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'_parse_args'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_parse_args_stats'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_parse_args_rvs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torchvision\n",
    "from skimage import io, transform\n",
    "from skimage import color\n",
    "import scipy.misc\n",
    "import scipy.ndimage as ndi\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from pytvision import visualization as view\n",
    "from pytvision.transforms import transforms as mtrans\n",
    "from tqdm import tqdm\n",
    "sys.path.append('../')\n",
    "from torchlib.datasets import dsxbdata\n",
    "from torchlib.datasets.dsxbdata import DSXBExDataset, DSXBDataset\n",
    "from torchlib.datasets import imageutl as imutl\n",
    "from torchlib import utils\n",
    "from torchlib.models import unetpad\n",
    "from torchlib.metrics import get_metrics\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#matplotlib.style.use('fivethirtyeight')\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "from pytvision.transforms import transforms as mtrans\n",
    "from torchlib import metrics\n",
    "\n",
    "from torchlib.segneuralnet import SegmentationNeuralNet\n",
    "from torchlib import post_processing_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_post  = post_processing_func.MAP_post()\n",
    "th_post   = post_processing_func.TH_post()\n",
    "wts_post  = post_processing_func.WTS_post()\n",
    "\n",
    "normalize = mtrans.ToMeanNormalization(\n",
    "    mean = (0.485, 0.456, 0.406),  \n",
    "    std  = (0.229, 0.224, 0.225), \n",
    "    )\n",
    "\n",
    "class NormalizeInverse(torchvision.transforms.Normalize):\n",
    "    \"\"\"\n",
    "    Undoes the normalization and returns the reconstructed images in the input domain.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mean = (0.485, 0.456, 0.406), std  = (0.229, 0.224, 0.225)):\n",
    "        mean     = torch.as_tensor(mean)\n",
    "        std      = torch.as_tensor(std)\n",
    "        std_inv  = 1 / (std + 1e-7)\n",
    "        mean_inv = -mean * std_inv\n",
    "        super().__init__(mean=mean_inv, std=std_inv)\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        return super().__call__(tensor.clone())\n",
    "\n",
    "n = NormalizeInverse()\n",
    "\n",
    "def get_simple_transforms(pad=0):\n",
    "    return transforms.Compose([\n",
    "        #mtrans.CenterCrop( (1008, 1008) ),\n",
    "        mtrans.ToPad( pad, pad, padding_mode=cv2.BORDER_CONSTANT ),\n",
    "        mtrans.ToTensor(),\n",
    "        normalize,      \n",
    "    ])\n",
    "\n",
    "\n",
    "def get_flip_transforms(pad=0):\n",
    "    return transforms.Compose([\n",
    "        #mtrans.CenterCrop( (1008, 1008) ),\n",
    "        mtrans.ToRandomTransform( mtrans.VFlip(), prob=0.5 ),\n",
    "        mtrans.ToRandomTransform( mtrans.HFlip(), prob=0.5 ),\n",
    "        \n",
    "        mtrans.ToPad( pad, pad, padding_mode=cv2.BORDER_CONSTANT ),\n",
    "        mtrans.ToTensor(),\n",
    "        normalize,      \n",
    "    ])\n",
    "\n",
    "def tensor2image(tensor, norm_inverse=True):\n",
    "    if tensor.dim() == 4:\n",
    "        tensor = tensor[0]\n",
    "    if norm_inverse:\n",
    "            tensor = n(tensor)\n",
    "    img = tensor.cpu().numpy().transpose(1,2,0)\n",
    "    img = (img * 255).clip(0, 255).astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "def show(src, titles=[], suptitle=\"\", \n",
    "         bwidth=4, bheight=4, save_file=False,\n",
    "         show_axis=True, show_cbar=False, last_max=0):\n",
    "\n",
    "    num_cols = len(src)\n",
    "    \n",
    "    plt.figure(figsize=(bwidth * num_cols, bheight))\n",
    "    plt.suptitle(suptitle)\n",
    "\n",
    "    for idx in range(num_cols):\n",
    "        plt.subplot(1, num_cols, idx+1)\n",
    "        if not show_axis: plt.axis(\"off\")\n",
    "        if idx < len(titles): plt.title(titles[idx])\n",
    "        \n",
    "        if idx == num_cols-1 and last_max:\n",
    "            plt.imshow(src[idx]*1, vmax=last_max, vmin=0)\n",
    "        else:\n",
    "            plt.imshow(src[idx]*1)\n",
    "        if type(show_cbar) is bool:\n",
    "            if show_cbar: plt.colorbar()\n",
    "        elif idx < len(show_cbar) and show_cbar[idx]:\n",
    "            plt.colorbar()\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    if save_file:\n",
    "        plt.savefig(save_file)\n",
    "        \n",
    "def show2(src, titles=[], suptitle=\"\", \n",
    "         bwidth=4, bheight=4, save_file=False,\n",
    "         show_axis=True, show_cbar=False, last_max=0):\n",
    "\n",
    "    num_cols = len(src)//2\n",
    "    \n",
    "    plt.figure(figsize=(bwidth * num_cols, bheight*2))\n",
    "    plt.suptitle(suptitle)\n",
    "\n",
    "    for idx in range(num_cols*2):\n",
    "        plt.subplot(2, num_cols, idx+1)\n",
    "        if not show_axis: plt.axis(\"off\")\n",
    "        if idx < len(titles): plt.title(titles[idx])\n",
    "        \n",
    "        if idx == num_cols-1 and last_max:\n",
    "            plt.imshow(src[idx]*1, vmax=last_max, vmin=0)\n",
    "        else:\n",
    "            plt.imshow(src[idx]*1)\n",
    "        if type(show_cbar) is bool:\n",
    "            if show_cbar: plt.colorbar()\n",
    "        elif idx < len(show_cbar) and show_cbar[idx]:\n",
    "            plt.colorbar()\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    if save_file:\n",
    "        plt.savefig(save_file)\n",
    "        \n",
    "def get_diversity_map(preds, gt_predictionlb, th=0.5):\n",
    "    max_iou = 0\n",
    "    diversity_map = np.zeros_like(gt_predictionlb)\n",
    "    for idx_gt in range(1, gt_predictionlb.max()):\n",
    "        roi = (gt_predictionlb==idx_gt)\n",
    "        max_iou = 0\n",
    "\n",
    "        for predlb in preds:\n",
    "            for idx_pred in range(1, predlb.max()):\n",
    "                roi_pred  = (predlb==idx_pred)\n",
    "                union = roi.astype(int) + roi_pred.astype(int)\n",
    "                val, freq = np.unique(union, return_counts=True)\n",
    "\n",
    "                if len(val)==3:\n",
    "                    iou = freq[2]/(freq[1]+freq[2])\n",
    "                    if iou > max_iou:\n",
    "                        max_iou = iou\n",
    "                if max_iou > th: break\n",
    "            if max_iou >th:\n",
    "                diversity_map += roi\n",
    "    return diversity_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(full_url, use_cuda=False, gpu_id=0):\n",
    "    full_path     = str(full_url)\n",
    "    splits        = full_path.split(r\"/\")\n",
    "    patchproject  = r'/'.join(splits[:10])\n",
    "    ckpt_path     = '/'.join(splits[11:])\n",
    "    exp_type, nameproject, _, file_name = splits[-4:]\n",
    "    \n",
    "    net = SegmentationNeuralNet(\n",
    "        patchproject=patchproject, \n",
    "        nameproject=nameproject, \n",
    "        no_cuda=not use_cuda, parallel=False, seed=2021, \n",
    "        print_freq=False, gpu=gpu_id\n",
    "    )\n",
    "\n",
    "    if net.load( full_path ) is not True:\n",
    "        print(\"Not Found Warring: \",full_path)\n",
    "        return False, net, None\n",
    "    \n",
    "    save_path = r'extra/' + '_'.join(np.array(splits)[[10, 12]]) + r'/'\n",
    "    Path(save_path).mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    if use_cuda:\n",
    "        net.cuda(gpu_id)\n",
    "    net.net.eval()\n",
    "    \n",
    "    return True, net, save_path\n",
    "\n",
    "def load_data(pathname, subset, use_cuda=False):\n",
    "    data = dsxbdata.ISBIDataset(\n",
    "        pathname, subset, \n",
    "        folders_labels=f'labels{num_classes}c',\n",
    "        count=None, num_classes=num_classes,\n",
    "        num_channels=num_channels,\n",
    "        transform=get_simple_transforms(pad=0),\n",
    "        use_weight=False, weight_name='',\n",
    "        load_segments=False, shuffle_segments=True,\n",
    "        use_ori=1\n",
    "    )\n",
    "\n",
    "    data_loader = DataLoader(data, batch_size=1, shuffle=False, \n",
    "        num_workers=0, pin_memory=use_cuda, drop_last=False)\n",
    "    \n",
    "    return data_loader\n",
    "\n",
    "def forward(net, sample, use_cuda=False, gpu_id=0, post_label='map'):\n",
    "    inputs, labels = sample['image'], sample['label']\n",
    "    \n",
    "    if use_cuda:\n",
    "        inputs = inputs.cuda(gpu_id)\n",
    "        \n",
    "    outputs     = net(inputs).cpu()\n",
    "    amax        = outputs[0].argmax(0)\n",
    "    view_inputs = tensor2image(inputs[0, :3])\n",
    "    view_labels = labels[0].argmax(0)\n",
    "    prob        = outputs[0] / outputs[0].sum(0)\n",
    "    \n",
    "    return  labels, outputs, amax, view_inputs, view_labels, prob\n",
    "\n",
    "def update_metrics(results, wpq, wsq, wrq, pcells, total_cells):\n",
    "\n",
    "    wpq += results['pq'] * n_cells\n",
    "    wsq += results['sq'] * n_cells\n",
    "    wrq += results['rq'] * n_cells\n",
    "    pcells += results['n_cells']\n",
    "    total_cells += n_cells\n",
    "\n",
    "    return wpq, wsq, wrq, pcells, total_cells\n",
    "\n",
    "def show_cells(results, n_cells, \n",
    "               v_inputs, v_labels, amax, predictionlb, prob,\n",
    "               save_path, namedataset, subset, idx):\n",
    "    \n",
    "    res_str = f\"Nreal {n_cells} | Npred {results['n_cells']} | PQ {results['pq']:0.2f} \" + \\\n",
    "            f\"| SQ {results['sq']:0.2f} | RQ {results['rq']:0.2f}\"\n",
    "\n",
    "    show2([v_inputs, v_labels, amax, predictionlb, prob[0], prob[1], prob[2], prob[3]], \n",
    "         show_axis=False, suptitle=res_str,\n",
    "         show_cbar=[False, False, False, False, True, True, True, True], \n",
    "         save_file=f\"{save_path}/{namedataset}_{subset}_{idx:03d}.jpg\",\n",
    "         titles=['Original', 'Label', 'MAP', 'Cells', 'Prob 0', 'Prob 1', 'Prob 2', 'Prob 3'], bheight=4.5)\n",
    "\n",
    "\n",
    "def write_logger(namedataset, subset, num_images, model_url_base, \n",
    "                 wpq, wsq, wrq, pcells, total_cells, summary_log=\"extra/summary.csv\"):\n",
    "    \n",
    "    row = [namedataset, subset, model_url_base, wpq/total_cells, \n",
    "           wsq/total_cells, wrq/total_cells, pcells, total_cells, num_images]\n",
    "    row = list(map(str, row))\n",
    "    header = [\"dataset\", 'subset', 'model', 'WPQ', 'WSQ', \"WRQ\", \"PCells\", \"Cells\", 'Images']\n",
    "        \n",
    "    write_header = not Path(summary_log).exists()\n",
    "    with open(summary_log, 'a') as f:\n",
    "        if write_header:\n",
    "            f.writelines(','.join(header)+'\\n')\n",
    "        f.writelines(','.join(row)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erro analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = torch.nn.Softmax(dim=0)\n",
    "\n",
    "\n",
    "pathdataset      = os.path.expanduser( '/home/chcp/Datasets' )\n",
    "\n",
    "#namedataset      = 'Seg33_1.0.4'\n",
    "#namedataset      = 'Seg1009_0.3.2'\n",
    "namedataset       = 'FluoC2DLMSC_0.1.1'\n",
    "#namedataset      = 'Bfhsc_1.0.0'\n",
    "\n",
    "folders_images   = 'images'\n",
    "folders_contours = 'touchs'\n",
    "folders_weights  = 'weights'\n",
    "folders_segment  = 'outputs'\n",
    "num_classes      = 4\n",
    "num_channels     = 3\n",
    "pathname         = pathdataset + '//' + namedataset\n",
    "\n",
    "use_cuda, gpu_id = False, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note: Change to all models\n",
    "model_list =  [Path(url) for url in glob(\n",
    "    r'/home/chcp/Documents/Mestrado/MedicalImageSegmentation/Projects/pytorch-unet/out/Fluo/baseline_*/models/model_best*')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_label = 'map'\n",
    "\n",
    "for model_url_base in tqdm(model_list):\n",
    "    \n",
    "    err, net, save_path = load_model(model_url_base, use_cuda, gpu_id)\n",
    "    \n",
    "    for subset in ['test', 'train', 'val']:\n",
    "    \n",
    "        data_loader      = load_data(pathname, subset)\n",
    "        num_images       = len(data_loader)\n",
    "        wpq, wsq, wrq, pcells, total_cells = 0, 0, 0, 0, 0\n",
    "\n",
    "        for idx, sample in enumerate(data_loader):\n",
    "            \n",
    "            labels, outputs, amax, v_inputs, v_labels, prob = forward(net, sample, use_cuda, gpu_id, post_label)\n",
    "            results, n_cells, preds = get_metrics(labels, outputs, post_label=post_label)\n",
    "            predictionlb, prediction, region, _ = preds\n",
    "            wpq, wsq, wrq, pcells, total_cells = update_metrics(results, wpq, wsq, wrq, pcells, total_cells)\n",
    "            \n",
    "            show_cells(results, n_cells, \n",
    "               v_inputs, v_labels, amax, predictionlb, prob,\n",
    "               save_path, namedataset, subset, idx)\n",
    "            \n",
    "        write_logger(namedataset, subset, num_images, model_url_base, \n",
    "                     wpq, wsq, wrq, pcells, total_cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diverse Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
